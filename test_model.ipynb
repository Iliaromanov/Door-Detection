{
 "cells": [
  {
   "source": [
    "## Data Analysis/Visualization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Type  Distance0  Distance1  Distance2  Distance3  Distance4  Distance5  \\\n",
       "0     1        147        277        173        233        268        226   \n",
       "1     1         96        265        184        175        107        116   \n",
       "2     1        244         12        204        299          9        173   \n",
       "3     0         42        208        182        121        227         17   \n",
       "4     0         45        271        144         36        292        119   \n",
       "5     0         92        296        220        275         46        200   \n",
       "6     1        267        212        205          9        256        292   \n",
       "7     0        248        122        108        111        190        202   \n",
       "8     1        228        217        159          3         99          1   \n",
       "9     1         49         98         43        215         73        200   \n",
       "\n",
       "   Distance6  Distance7  Distance8  ...  Distance80  Distance81  Distance82  \\\n",
       "0        231        103        118  ...         264         197         185   \n",
       "1         49         97        144  ...         278         298         236   \n",
       "2        140         20        133  ...         271         239          92   \n",
       "3        115         38         26  ...         284         115         138   \n",
       "4        266         56         66  ...         278          18          92   \n",
       "5         29        218         61  ...          65         194         251   \n",
       "6        292        179        115  ...         208         199          44   \n",
       "7        111        186        122  ...          48         227         227   \n",
       "8        229        123        292  ...          15         177         272   \n",
       "9        237         81         39  ...          31           9         152   \n",
       "\n",
       "   Distance83  Distance84  Distance85  Distance86  Distance87  Distance88  \\\n",
       "0         254         243         234         205         299         201   \n",
       "1          70          53         270         125         272         235   \n",
       "2         198         136         189         131         164         140   \n",
       "3         102         206          69         258         156          74   \n",
       "4          10          47         192         162         200         115   \n",
       "5         250         126         166         125          67          12   \n",
       "6          43          84          99         299         116         210   \n",
       "7          36         187          49         291         238          58   \n",
       "8          75          47         156         160         133          86   \n",
       "9          80         241          19         205          13          97   \n",
       "\n",
       "   Distance89  \n",
       "0         264  \n",
       "1         224  \n",
       "2          80  \n",
       "3         200  \n",
       "4         106  \n",
       "5         159  \n",
       "6         104  \n",
       "7         193  \n",
       "8          54  \n",
       "9         266  \n",
       "\n",
       "[10 rows x 91 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Distance0</th>\n      <th>Distance1</th>\n      <th>Distance2</th>\n      <th>Distance3</th>\n      <th>Distance4</th>\n      <th>Distance5</th>\n      <th>Distance6</th>\n      <th>Distance7</th>\n      <th>Distance8</th>\n      <th>...</th>\n      <th>Distance80</th>\n      <th>Distance81</th>\n      <th>Distance82</th>\n      <th>Distance83</th>\n      <th>Distance84</th>\n      <th>Distance85</th>\n      <th>Distance86</th>\n      <th>Distance87</th>\n      <th>Distance88</th>\n      <th>Distance89</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>147</td>\n      <td>277</td>\n      <td>173</td>\n      <td>233</td>\n      <td>268</td>\n      <td>226</td>\n      <td>231</td>\n      <td>103</td>\n      <td>118</td>\n      <td>...</td>\n      <td>264</td>\n      <td>197</td>\n      <td>185</td>\n      <td>254</td>\n      <td>243</td>\n      <td>234</td>\n      <td>205</td>\n      <td>299</td>\n      <td>201</td>\n      <td>264</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>96</td>\n      <td>265</td>\n      <td>184</td>\n      <td>175</td>\n      <td>107</td>\n      <td>116</td>\n      <td>49</td>\n      <td>97</td>\n      <td>144</td>\n      <td>...</td>\n      <td>278</td>\n      <td>298</td>\n      <td>236</td>\n      <td>70</td>\n      <td>53</td>\n      <td>270</td>\n      <td>125</td>\n      <td>272</td>\n      <td>235</td>\n      <td>224</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>244</td>\n      <td>12</td>\n      <td>204</td>\n      <td>299</td>\n      <td>9</td>\n      <td>173</td>\n      <td>140</td>\n      <td>20</td>\n      <td>133</td>\n      <td>...</td>\n      <td>271</td>\n      <td>239</td>\n      <td>92</td>\n      <td>198</td>\n      <td>136</td>\n      <td>189</td>\n      <td>131</td>\n      <td>164</td>\n      <td>140</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>42</td>\n      <td>208</td>\n      <td>182</td>\n      <td>121</td>\n      <td>227</td>\n      <td>17</td>\n      <td>115</td>\n      <td>38</td>\n      <td>26</td>\n      <td>...</td>\n      <td>284</td>\n      <td>115</td>\n      <td>138</td>\n      <td>102</td>\n      <td>206</td>\n      <td>69</td>\n      <td>258</td>\n      <td>156</td>\n      <td>74</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>45</td>\n      <td>271</td>\n      <td>144</td>\n      <td>36</td>\n      <td>292</td>\n      <td>119</td>\n      <td>266</td>\n      <td>56</td>\n      <td>66</td>\n      <td>...</td>\n      <td>278</td>\n      <td>18</td>\n      <td>92</td>\n      <td>10</td>\n      <td>47</td>\n      <td>192</td>\n      <td>162</td>\n      <td>200</td>\n      <td>115</td>\n      <td>106</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>92</td>\n      <td>296</td>\n      <td>220</td>\n      <td>275</td>\n      <td>46</td>\n      <td>200</td>\n      <td>29</td>\n      <td>218</td>\n      <td>61</td>\n      <td>...</td>\n      <td>65</td>\n      <td>194</td>\n      <td>251</td>\n      <td>250</td>\n      <td>126</td>\n      <td>166</td>\n      <td>125</td>\n      <td>67</td>\n      <td>12</td>\n      <td>159</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>267</td>\n      <td>212</td>\n      <td>205</td>\n      <td>9</td>\n      <td>256</td>\n      <td>292</td>\n      <td>292</td>\n      <td>179</td>\n      <td>115</td>\n      <td>...</td>\n      <td>208</td>\n      <td>199</td>\n      <td>44</td>\n      <td>43</td>\n      <td>84</td>\n      <td>99</td>\n      <td>299</td>\n      <td>116</td>\n      <td>210</td>\n      <td>104</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>248</td>\n      <td>122</td>\n      <td>108</td>\n      <td>111</td>\n      <td>190</td>\n      <td>202</td>\n      <td>111</td>\n      <td>186</td>\n      <td>122</td>\n      <td>...</td>\n      <td>48</td>\n      <td>227</td>\n      <td>227</td>\n      <td>36</td>\n      <td>187</td>\n      <td>49</td>\n      <td>291</td>\n      <td>238</td>\n      <td>58</td>\n      <td>193</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>228</td>\n      <td>217</td>\n      <td>159</td>\n      <td>3</td>\n      <td>99</td>\n      <td>1</td>\n      <td>229</td>\n      <td>123</td>\n      <td>292</td>\n      <td>...</td>\n      <td>15</td>\n      <td>177</td>\n      <td>272</td>\n      <td>75</td>\n      <td>47</td>\n      <td>156</td>\n      <td>160</td>\n      <td>133</td>\n      <td>86</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>49</td>\n      <td>98</td>\n      <td>43</td>\n      <td>215</td>\n      <td>73</td>\n      <td>200</td>\n      <td>237</td>\n      <td>81</td>\n      <td>39</td>\n      <td>...</td>\n      <td>31</td>\n      <td>9</td>\n      <td>152</td>\n      <td>80</td>\n      <td>241</td>\n      <td>19</td>\n      <td>205</td>\n      <td>13</td>\n      <td>97</td>\n      <td>266</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 91 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            Type  Distance0   Distance1   Distance2   Distance3   Distance4  \\\n",
       "count  10.000000   10.00000   10.000000   10.000000   10.000000   10.000000   \n",
       "mean    0.600000  145.80000  197.800000  162.200000  147.700000  156.700000   \n",
       "std     0.516398   92.62565   92.310828   53.115806  108.709654  101.915052   \n",
       "min     0.000000   42.00000   12.000000   43.000000    3.000000    9.000000   \n",
       "25%     0.000000   59.75000  143.500000  147.750000   54.750000   79.500000   \n",
       "50%     1.000000  121.50000  214.500000  177.500000  148.000000  148.500000   \n",
       "75%     1.000000  240.00000  269.500000  199.000000  228.500000  248.750000   \n",
       "max     1.000000  267.00000  296.000000  220.000000  299.000000  292.000000   \n",
       "\n",
       "        Distance5   Distance6   Distance7   Distance8  ...  Distance80  \\\n",
       "count   10.000000   10.000000   10.000000   10.000000  ...    10.00000   \n",
       "mean   154.600000  169.900000  110.100000  111.600000  ...   174.20000   \n",
       "std     91.874552   92.927032   66.356696   75.608935  ...   118.26693   \n",
       "min      1.000000   29.000000   20.000000   26.000000  ...    15.00000   \n",
       "25%    116.750000  112.000000   62.250000   62.250000  ...    52.25000   \n",
       "50%    186.500000  184.500000  100.000000  116.500000  ...   236.00000   \n",
       "75%    201.500000  235.500000  165.000000  130.250000  ...   276.25000   \n",
       "max    292.000000  292.000000  218.000000  292.000000  ...   284.00000   \n",
       "\n",
       "       Distance81  Distance82  Distance83  Distance84  Distance85  Distance86  \\\n",
       "count    10.00000   10.000000   10.000000   10.000000   10.000000   10.000000   \n",
       "mean    167.30000  168.900000  111.800000  137.000000  144.300000  196.100000   \n",
       "std      93.43215   77.585007   89.319402   78.528127   82.483736   66.998259   \n",
       "min       9.00000   44.000000   10.000000   47.000000   19.000000  125.000000   \n",
       "25%     130.50000  103.500000   49.750000   60.750000   76.500000  138.250000   \n",
       "50%     195.50000  168.500000   77.500000  131.000000  161.000000  183.500000   \n",
       "75%     220.00000  233.750000  174.000000  201.250000  191.250000  244.750000   \n",
       "max     298.00000  272.000000  254.000000  243.000000  270.000000  299.000000   \n",
       "\n",
       "       Distance87  Distance88  Distance89  \n",
       "count    10.00000   10.000000   10.000000  \n",
       "mean    165.80000  122.800000  165.000000  \n",
       "std      89.54676   72.680121   76.213151  \n",
       "min      13.00000   12.000000   54.000000  \n",
       "25%     120.25000   77.000000  104.500000  \n",
       "50%     160.00000  106.000000  176.000000  \n",
       "75%     228.50000  185.750000  218.000000  \n",
       "max     299.00000  235.000000  266.000000  \n",
       "\n",
       "[8 rows x 91 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Type</th>\n      <th>Distance0</th>\n      <th>Distance1</th>\n      <th>Distance2</th>\n      <th>Distance3</th>\n      <th>Distance4</th>\n      <th>Distance5</th>\n      <th>Distance6</th>\n      <th>Distance7</th>\n      <th>Distance8</th>\n      <th>...</th>\n      <th>Distance80</th>\n      <th>Distance81</th>\n      <th>Distance82</th>\n      <th>Distance83</th>\n      <th>Distance84</th>\n      <th>Distance85</th>\n      <th>Distance86</th>\n      <th>Distance87</th>\n      <th>Distance88</th>\n      <th>Distance89</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10.000000</td>\n      <td>10.00000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>...</td>\n      <td>10.00000</td>\n      <td>10.00000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.00000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.600000</td>\n      <td>145.80000</td>\n      <td>197.800000</td>\n      <td>162.200000</td>\n      <td>147.700000</td>\n      <td>156.700000</td>\n      <td>154.600000</td>\n      <td>169.900000</td>\n      <td>110.100000</td>\n      <td>111.600000</td>\n      <td>...</td>\n      <td>174.20000</td>\n      <td>167.30000</td>\n      <td>168.900000</td>\n      <td>111.800000</td>\n      <td>137.000000</td>\n      <td>144.300000</td>\n      <td>196.100000</td>\n      <td>165.80000</td>\n      <td>122.800000</td>\n      <td>165.000000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.516398</td>\n      <td>92.62565</td>\n      <td>92.310828</td>\n      <td>53.115806</td>\n      <td>108.709654</td>\n      <td>101.915052</td>\n      <td>91.874552</td>\n      <td>92.927032</td>\n      <td>66.356696</td>\n      <td>75.608935</td>\n      <td>...</td>\n      <td>118.26693</td>\n      <td>93.43215</td>\n      <td>77.585007</td>\n      <td>89.319402</td>\n      <td>78.528127</td>\n      <td>82.483736</td>\n      <td>66.998259</td>\n      <td>89.54676</td>\n      <td>72.680121</td>\n      <td>76.213151</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>42.00000</td>\n      <td>12.000000</td>\n      <td>43.000000</td>\n      <td>3.000000</td>\n      <td>9.000000</td>\n      <td>1.000000</td>\n      <td>29.000000</td>\n      <td>20.000000</td>\n      <td>26.000000</td>\n      <td>...</td>\n      <td>15.00000</td>\n      <td>9.00000</td>\n      <td>44.000000</td>\n      <td>10.000000</td>\n      <td>47.000000</td>\n      <td>19.000000</td>\n      <td>125.000000</td>\n      <td>13.00000</td>\n      <td>12.000000</td>\n      <td>54.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>59.75000</td>\n      <td>143.500000</td>\n      <td>147.750000</td>\n      <td>54.750000</td>\n      <td>79.500000</td>\n      <td>116.750000</td>\n      <td>112.000000</td>\n      <td>62.250000</td>\n      <td>62.250000</td>\n      <td>...</td>\n      <td>52.25000</td>\n      <td>130.50000</td>\n      <td>103.500000</td>\n      <td>49.750000</td>\n      <td>60.750000</td>\n      <td>76.500000</td>\n      <td>138.250000</td>\n      <td>120.25000</td>\n      <td>77.000000</td>\n      <td>104.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>121.50000</td>\n      <td>214.500000</td>\n      <td>177.500000</td>\n      <td>148.000000</td>\n      <td>148.500000</td>\n      <td>186.500000</td>\n      <td>184.500000</td>\n      <td>100.000000</td>\n      <td>116.500000</td>\n      <td>...</td>\n      <td>236.00000</td>\n      <td>195.50000</td>\n      <td>168.500000</td>\n      <td>77.500000</td>\n      <td>131.000000</td>\n      <td>161.000000</td>\n      <td>183.500000</td>\n      <td>160.00000</td>\n      <td>106.000000</td>\n      <td>176.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>240.00000</td>\n      <td>269.500000</td>\n      <td>199.000000</td>\n      <td>228.500000</td>\n      <td>248.750000</td>\n      <td>201.500000</td>\n      <td>235.500000</td>\n      <td>165.000000</td>\n      <td>130.250000</td>\n      <td>...</td>\n      <td>276.25000</td>\n      <td>220.00000</td>\n      <td>233.750000</td>\n      <td>174.000000</td>\n      <td>201.250000</td>\n      <td>191.250000</td>\n      <td>244.750000</td>\n      <td>228.50000</td>\n      <td>185.750000</td>\n      <td>218.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>267.00000</td>\n      <td>296.000000</td>\n      <td>220.000000</td>\n      <td>299.000000</td>\n      <td>292.000000</td>\n      <td>292.000000</td>\n      <td>292.000000</td>\n      <td>218.000000</td>\n      <td>292.000000</td>\n      <td>...</td>\n      <td>284.00000</td>\n      <td>298.00000</td>\n      <td>272.000000</td>\n      <td>254.000000</td>\n      <td>243.000000</td>\n      <td>270.000000</td>\n      <td>299.000000</td>\n      <td>299.00000</td>\n      <td>235.000000</td>\n      <td>266.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 91 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "source": [
    "## Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "columns = df.columns\n",
    "\n",
    "X = df[columns[1:]]\n",
    "y = df['Type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Distance0  Distance1  Distance2  Distance3  Distance4  Distance5  \\\n",
       "0        147        277        173        233        268        226   \n",
       "1         96        265        184        175        107        116   \n",
       "2        244         12        204        299          9        173   \n",
       "3         42        208        182        121        227         17   \n",
       "4         45        271        144         36        292        119   \n",
       "\n",
       "   Distance6  Distance7  Distance8  Distance9  ...  Distance80  Distance81  \\\n",
       "0        231        103        118         45  ...         264         197   \n",
       "1         49         97        144        276  ...         278         298   \n",
       "2        140         20        133        198  ...         271         239   \n",
       "3        115         38         26        216  ...         284         115   \n",
       "4        266         56         66        183  ...         278          18   \n",
       "\n",
       "   Distance82  Distance83  Distance84  Distance85  Distance86  Distance87  \\\n",
       "0         185         254         243         234         205         299   \n",
       "1         236          70          53         270         125         272   \n",
       "2          92         198         136         189         131         164   \n",
       "3         138         102         206          69         258         156   \n",
       "4          92          10          47         192         162         200   \n",
       "\n",
       "   Distance88  Distance89  \n",
       "0         201         264  \n",
       "1         235         224  \n",
       "2         140          80  \n",
       "3          74         200  \n",
       "4         115         106  \n",
       "\n",
       "[5 rows x 90 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Distance0</th>\n      <th>Distance1</th>\n      <th>Distance2</th>\n      <th>Distance3</th>\n      <th>Distance4</th>\n      <th>Distance5</th>\n      <th>Distance6</th>\n      <th>Distance7</th>\n      <th>Distance8</th>\n      <th>Distance9</th>\n      <th>...</th>\n      <th>Distance80</th>\n      <th>Distance81</th>\n      <th>Distance82</th>\n      <th>Distance83</th>\n      <th>Distance84</th>\n      <th>Distance85</th>\n      <th>Distance86</th>\n      <th>Distance87</th>\n      <th>Distance88</th>\n      <th>Distance89</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>147</td>\n      <td>277</td>\n      <td>173</td>\n      <td>233</td>\n      <td>268</td>\n      <td>226</td>\n      <td>231</td>\n      <td>103</td>\n      <td>118</td>\n      <td>45</td>\n      <td>...</td>\n      <td>264</td>\n      <td>197</td>\n      <td>185</td>\n      <td>254</td>\n      <td>243</td>\n      <td>234</td>\n      <td>205</td>\n      <td>299</td>\n      <td>201</td>\n      <td>264</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>96</td>\n      <td>265</td>\n      <td>184</td>\n      <td>175</td>\n      <td>107</td>\n      <td>116</td>\n      <td>49</td>\n      <td>97</td>\n      <td>144</td>\n      <td>276</td>\n      <td>...</td>\n      <td>278</td>\n      <td>298</td>\n      <td>236</td>\n      <td>70</td>\n      <td>53</td>\n      <td>270</td>\n      <td>125</td>\n      <td>272</td>\n      <td>235</td>\n      <td>224</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>244</td>\n      <td>12</td>\n      <td>204</td>\n      <td>299</td>\n      <td>9</td>\n      <td>173</td>\n      <td>140</td>\n      <td>20</td>\n      <td>133</td>\n      <td>198</td>\n      <td>...</td>\n      <td>271</td>\n      <td>239</td>\n      <td>92</td>\n      <td>198</td>\n      <td>136</td>\n      <td>189</td>\n      <td>131</td>\n      <td>164</td>\n      <td>140</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>42</td>\n      <td>208</td>\n      <td>182</td>\n      <td>121</td>\n      <td>227</td>\n      <td>17</td>\n      <td>115</td>\n      <td>38</td>\n      <td>26</td>\n      <td>216</td>\n      <td>...</td>\n      <td>284</td>\n      <td>115</td>\n      <td>138</td>\n      <td>102</td>\n      <td>206</td>\n      <td>69</td>\n      <td>258</td>\n      <td>156</td>\n      <td>74</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>45</td>\n      <td>271</td>\n      <td>144</td>\n      <td>36</td>\n      <td>292</td>\n      <td>119</td>\n      <td>266</td>\n      <td>56</td>\n      <td>66</td>\n      <td>183</td>\n      <td>...</td>\n      <td>278</td>\n      <td>18</td>\n      <td>92</td>\n      <td>10</td>\n      <td>47</td>\n      <td>192</td>\n      <td>162</td>\n      <td>200</td>\n      <td>115</td>\n      <td>106</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 90 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: Type, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 90)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(30, activation = 'relu'))\n",
    "model.add(Dense(15, activation = 'relu'))\n",
    "\n",
    "# BINARY CLASSIFICATION\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.7747 - val_loss: 0.9294\n",
      "Epoch 2/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.7384 - val_loss: 0.9190\n",
      "Epoch 3/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7046 - val_loss: 0.9194\n",
      "Epoch 4/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6755 - val_loss: 0.9228\n",
      "Epoch 5/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6508 - val_loss: 0.9272\n",
      "Epoch 6/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6296 - val_loss: 0.9320\n",
      "Epoch 7/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6077 - val_loss: 0.9380\n",
      "Epoch 8/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5879 - val_loss: 0.9391\n",
      "Epoch 9/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5713 - val_loss: 0.9368\n",
      "Epoch 10/600\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5548 - val_loss: 0.9329\n",
      "Epoch 11/600\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5387 - val_loss: 0.9258\n",
      "Epoch 12/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5239 - val_loss: 0.9169\n",
      "Epoch 13/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5095 - val_loss: 0.9049\n",
      "Epoch 14/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4963 - val_loss: 0.8935\n",
      "Epoch 15/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4834 - val_loss: 0.8838\n",
      "Epoch 16/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4707 - val_loss: 0.8753\n",
      "Epoch 17/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4602 - val_loss: 0.8717\n",
      "Epoch 18/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4510 - val_loss: 0.8714\n",
      "Epoch 19/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4409 - val_loss: 0.8753\n",
      "Epoch 20/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4301 - val_loss: 0.8824\n",
      "Epoch 21/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4194 - val_loss: 0.8924\n",
      "Epoch 22/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4090 - val_loss: 0.9038\n",
      "Epoch 23/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3996 - val_loss: 0.9143\n",
      "Epoch 24/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3909 - val_loss: 0.9210\n",
      "Epoch 25/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3828 - val_loss: 0.9229\n",
      "Epoch 26/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3740 - val_loss: 0.9209\n",
      "Epoch 27/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3648 - val_loss: 0.9182\n",
      "Epoch 28/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3557 - val_loss: 0.9174\n",
      "Epoch 29/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3480 - val_loss: 0.9198\n",
      "Epoch 30/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3401 - val_loss: 0.9251\n",
      "Epoch 31/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3319 - val_loss: 0.9338\n",
      "Epoch 32/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3242 - val_loss: 0.9422\n",
      "Epoch 33/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3166 - val_loss: 0.9540\n",
      "Epoch 34/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3097 - val_loss: 0.9687\n",
      "Epoch 35/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3029 - val_loss: 0.9820\n",
      "Epoch 36/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2963 - val_loss: 0.9924\n",
      "Epoch 37/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2897 - val_loss: 1.0026\n",
      "Epoch 38/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2832 - val_loss: 1.0124\n",
      "Epoch 39/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2766 - val_loss: 1.0260\n",
      "Epoch 40/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2699 - val_loss: 1.0445\n",
      "Epoch 41/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2643 - val_loss: 1.0580\n",
      "Epoch 42/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2584 - val_loss: 1.0622\n",
      "Epoch 43/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2514 - val_loss: 1.0592\n",
      "Epoch 44/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2463 - val_loss: 1.0615\n",
      "Epoch 45/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2411 - val_loss: 1.0694\n",
      "Epoch 46/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2354 - val_loss: 1.0822\n",
      "Epoch 47/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2296 - val_loss: 1.0975\n",
      "Epoch 48/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2240 - val_loss: 1.1110\n",
      "Epoch 49/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2192 - val_loss: 1.1209\n",
      "Epoch 50/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2143 - val_loss: 1.1282\n",
      "Epoch 51/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2089 - val_loss: 1.1304\n",
      "Epoch 52/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2036 - val_loss: 1.1317\n",
      "Epoch 53/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1989 - val_loss: 1.1381\n",
      "Epoch 54/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1941 - val_loss: 1.1491\n",
      "Epoch 55/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1891 - val_loss: 1.1642\n",
      "Epoch 56/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1839 - val_loss: 1.1796\n",
      "Epoch 57/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1796 - val_loss: 1.1879\n",
      "Epoch 58/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1752 - val_loss: 1.1892\n",
      "Epoch 59/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1707 - val_loss: 1.1890\n",
      "Epoch 60/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1666 - val_loss: 1.1921\n",
      "Epoch 61/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1623 - val_loss: 1.1974\n",
      "Epoch 62/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1582 - val_loss: 1.2021\n",
      "Epoch 63/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1542 - val_loss: 1.2024\n",
      "Epoch 64/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1502 - val_loss: 1.2035\n",
      "Epoch 65/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1464 - val_loss: 1.2091\n",
      "Epoch 66/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1429 - val_loss: 1.2147\n",
      "Epoch 67/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1394 - val_loss: 1.2207\n",
      "Epoch 68/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1358 - val_loss: 1.2236\n",
      "Epoch 69/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1321 - val_loss: 1.2278\n",
      "Epoch 70/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1284 - val_loss: 1.2365\n",
      "Epoch 71/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1249 - val_loss: 1.2439\n",
      "Epoch 72/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1214 - val_loss: 1.2461\n",
      "Epoch 73/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1176 - val_loss: 1.2533\n",
      "Epoch 74/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1141 - val_loss: 1.2634\n",
      "Epoch 75/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1105 - val_loss: 1.2716\n",
      "Epoch 76/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1069 - val_loss: 1.2758\n",
      "Epoch 77/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1034 - val_loss: 1.2840\n",
      "Epoch 78/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1001 - val_loss: 1.2890\n",
      "Epoch 79/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0969 - val_loss: 1.2910\n",
      "Epoch 80/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0937 - val_loss: 1.2938\n",
      "Epoch 81/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0907 - val_loss: 1.2989\n",
      "Epoch 82/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0877 - val_loss: 1.3035\n",
      "Epoch 83/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0848 - val_loss: 1.3083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0821 - val_loss: 1.3072\n",
      "Epoch 85/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0794 - val_loss: 1.3051\n",
      "Epoch 86/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0769 - val_loss: 1.3082\n",
      "Epoch 87/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0745 - val_loss: 1.3165\n",
      "Epoch 88/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0720 - val_loss: 1.3292\n",
      "Epoch 89/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0697 - val_loss: 1.3348\n",
      "Epoch 90/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0675 - val_loss: 1.3379\n",
      "Epoch 91/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0652 - val_loss: 1.3379\n",
      "Epoch 92/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0632 - val_loss: 1.3400\n",
      "Epoch 93/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0612 - val_loss: 1.3460\n",
      "Epoch 94/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0593 - val_loss: 1.3555\n",
      "Epoch 95/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0573 - val_loss: 1.3641\n",
      "Epoch 96/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0556 - val_loss: 1.3693\n",
      "Epoch 97/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0539 - val_loss: 1.3730\n",
      "Epoch 98/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0523 - val_loss: 1.3785\n",
      "Epoch 99/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0507 - val_loss: 1.3839\n",
      "Epoch 100/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0491 - val_loss: 1.3892\n",
      "Epoch 101/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0476 - val_loss: 1.3963\n",
      "Epoch 102/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0463 - val_loss: 1.4032\n",
      "Epoch 103/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0449 - val_loss: 1.4096\n",
      "Epoch 104/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0436 - val_loss: 1.4159\n",
      "Epoch 105/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0424 - val_loss: 1.4248\n",
      "Epoch 106/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0411 - val_loss: 1.4344\n",
      "Epoch 107/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0400 - val_loss: 1.4440\n",
      "Epoch 108/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0389 - val_loss: 1.4494\n",
      "Epoch 109/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0378 - val_loss: 1.4528\n",
      "Epoch 110/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0368 - val_loss: 1.4588\n",
      "Epoch 111/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0358 - val_loss: 1.4668\n",
      "Epoch 112/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0348 - val_loss: 1.4755\n",
      "Epoch 113/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0339 - val_loss: 1.4811\n",
      "Epoch 114/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0330 - val_loss: 1.4881\n",
      "Epoch 115/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0322 - val_loss: 1.4981\n",
      "Epoch 116/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0314 - val_loss: 1.5083\n",
      "Epoch 117/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0306 - val_loss: 1.5178\n",
      "Epoch 118/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0299 - val_loss: 1.5242\n",
      "Epoch 119/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0291 - val_loss: 1.5287\n",
      "Epoch 120/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0284 - val_loss: 1.5317\n",
      "Epoch 121/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0278 - val_loss: 1.5366\n",
      "Epoch 122/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0271 - val_loss: 1.5427\n",
      "Epoch 123/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0265 - val_loss: 1.5498\n",
      "Epoch 124/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0259 - val_loss: 1.5578\n",
      "Epoch 125/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0253 - val_loss: 1.5660\n",
      "Epoch 126/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0247 - val_loss: 1.5710\n",
      "Epoch 127/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0241 - val_loss: 1.5742\n",
      "Epoch 128/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0236 - val_loss: 1.5779\n",
      "Epoch 129/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0231 - val_loss: 1.5830\n",
      "Epoch 130/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0226 - val_loss: 1.5885\n",
      "Epoch 131/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0221 - val_loss: 1.5942\n",
      "Epoch 132/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0217 - val_loss: 1.5982\n",
      "Epoch 133/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0212 - val_loss: 1.6010\n",
      "Epoch 134/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0208 - val_loss: 1.6048\n",
      "Epoch 135/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0203 - val_loss: 1.6118\n",
      "Epoch 136/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0199 - val_loss: 1.6188\n",
      "Epoch 137/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0195 - val_loss: 1.6213\n",
      "Epoch 138/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0191 - val_loss: 1.6254\n",
      "Epoch 139/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0188 - val_loss: 1.6298\n",
      "Epoch 140/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0184 - val_loss: 1.6356\n",
      "Epoch 141/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0181 - val_loss: 1.6396\n",
      "Epoch 142/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0177 - val_loss: 1.6448\n",
      "Epoch 143/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0174 - val_loss: 1.6509\n",
      "Epoch 144/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0171 - val_loss: 1.6567\n",
      "Epoch 145/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0167 - val_loss: 1.6621\n",
      "Epoch 146/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0164 - val_loss: 1.6629\n",
      "Epoch 147/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 1.6639\n",
      "Epoch 148/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0159 - val_loss: 1.6666\n",
      "Epoch 149/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0156 - val_loss: 1.6718\n",
      "Epoch 150/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 1.6786\n",
      "Epoch 151/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0150 - val_loss: 1.6835\n",
      "Epoch 152/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0148 - val_loss: 1.6870\n",
      "Epoch 153/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0145 - val_loss: 1.6904\n",
      "Epoch 154/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0143 - val_loss: 1.6946\n",
      "Epoch 155/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0140 - val_loss: 1.7004\n",
      "Epoch 156/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0138 - val_loss: 1.7058\n",
      "Epoch 157/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0135 - val_loss: 1.7094\n",
      "Epoch 158/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0133 - val_loss: 1.7121\n",
      "Epoch 159/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0131 - val_loss: 1.7161\n",
      "Epoch 160/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0129 - val_loss: 1.7192\n",
      "Epoch 161/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0127 - val_loss: 1.7235\n",
      "Epoch 162/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0125 - val_loss: 1.7279\n",
      "Epoch 163/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 1.7323\n",
      "Epoch 164/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0121 - val_loss: 1.7332\n",
      "Epoch 165/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0119 - val_loss: 1.7365\n",
      "Epoch 166/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 1.7415\n",
      "Epoch 167/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0115 - val_loss: 1.7466\n",
      "Epoch 168/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0114 - val_loss: 1.7506\n",
      "Epoch 169/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0112 - val_loss: 1.7535\n",
      "Epoch 170/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0110 - val_loss: 1.7582\n",
      "Epoch 171/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0109 - val_loss: 1.7635\n",
      "Epoch 172/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 1.7681\n",
      "Epoch 173/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0105 - val_loss: 1.7685\n",
      "Epoch 174/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 1.7691\n",
      "Epoch 175/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0102 - val_loss: 1.7712\n",
      "Epoch 176/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0101 - val_loss: 1.7754\n",
      "Epoch 177/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0099 - val_loss: 1.7793\n",
      "Epoch 178/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0098 - val_loss: 1.7820\n",
      "Epoch 179/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 1.7848\n",
      "Epoch 180/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 1.7877\n",
      "Epoch 181/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 1.7910\n",
      "Epoch 182/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 1.7940\n",
      "Epoch 183/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 1.7962\n",
      "Epoch 184/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 1.7990\n",
      "Epoch 185/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 1.8024\n",
      "Epoch 186/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0087 - val_loss: 1.8054\n",
      "Epoch 187/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 1.8095\n",
      "Epoch 188/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 1.8115\n",
      "Epoch 189/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 1.8147\n",
      "Epoch 190/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 1.8171\n",
      "Epoch 191/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0081 - val_loss: 1.8195\n",
      "Epoch 192/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 1.8225\n",
      "Epoch 193/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 1.8252\n",
      "Epoch 194/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0078 - val_loss: 1.8278\n",
      "Epoch 195/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0077 - val_loss: 1.8312\n",
      "Epoch 196/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 1.8333\n",
      "Epoch 197/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 1.8342\n",
      "Epoch 198/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0074 - val_loss: 1.8374\n",
      "Epoch 199/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0073 - val_loss: 1.8408\n",
      "Epoch 200/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 1.8433\n",
      "Epoch 201/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 1.8449\n",
      "Epoch 202/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0070 - val_loss: 1.8480\n",
      "Epoch 203/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 1.8523\n",
      "Epoch 204/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0068 - val_loss: 1.8567\n",
      "Epoch 205/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0067 - val_loss: 1.8590\n",
      "Epoch 206/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 1.8615\n",
      "Epoch 207/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 1.8640\n",
      "Epoch 208/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0065 - val_loss: 1.8665\n",
      "Epoch 209/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0064 - val_loss: 1.8684\n",
      "Epoch 210/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0063 - val_loss: 1.8709\n",
      "Epoch 211/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0062 - val_loss: 1.8732\n",
      "Epoch 212/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0062 - val_loss: 1.8756\n",
      "Epoch 213/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0061 - val_loss: 1.8789\n",
      "Epoch 214/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0060 - val_loss: 1.8819\n",
      "Epoch 215/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0060 - val_loss: 1.8839\n",
      "Epoch 216/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0059 - val_loss: 1.8864\n",
      "Epoch 217/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0058 - val_loss: 1.8893\n",
      "Epoch 218/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0058 - val_loss: 1.8924\n",
      "Epoch 219/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0057 - val_loss: 1.8929\n",
      "Epoch 220/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 1.8936\n",
      "Epoch 221/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0056 - val_loss: 1.8961\n",
      "Epoch 222/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0055 - val_loss: 1.9001\n",
      "Epoch 223/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 1.9039\n",
      "Epoch 224/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0054 - val_loss: 1.9064\n",
      "Epoch 225/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 1.9079\n",
      "Epoch 226/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0053 - val_loss: 1.9096\n",
      "Epoch 227/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0052 - val_loss: 1.9119\n",
      "Epoch 228/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 1.9147\n",
      "Epoch 229/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0051 - val_loss: 1.9179\n",
      "Epoch 230/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0050 - val_loss: 1.9208\n",
      "Epoch 231/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0050 - val_loss: 1.9220\n",
      "Epoch 232/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 1.9240\n",
      "Epoch 233/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0049 - val_loss: 1.9259\n",
      "Epoch 234/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 1.9288\n",
      "Epoch 235/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0048 - val_loss: 1.9314\n",
      "Epoch 236/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 1.9340\n",
      "Epoch 237/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0047 - val_loss: 1.9368\n",
      "Epoch 238/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0046 - val_loss: 1.9383\n",
      "Epoch 239/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0046 - val_loss: 1.9394\n",
      "Epoch 240/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 1.9404\n",
      "Epoch 241/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0045 - val_loss: 1.9429\n",
      "Epoch 242/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0044 - val_loss: 1.9457\n",
      "Epoch 243/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0044 - val_loss: 1.9468\n",
      "Epoch 244/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0043 - val_loss: 1.9476\n",
      "Epoch 245/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0043 - val_loss: 1.9484\n",
      "Epoch 246/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 1.9504\n",
      "Epoch 247/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0042 - val_loss: 1.9521\n",
      "Epoch 248/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 1.9530\n",
      "Epoch 249/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 1.9534\n",
      "Epoch 250/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0041 - val_loss: 1.9546\n",
      "Epoch 251/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 1.9560\n",
      "Epoch 252/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0040 - val_loss: 1.9571\n",
      "Epoch 253/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 1.9583\n",
      "Epoch 254/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0039 - val_loss: 1.9583\n",
      "Epoch 255/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 1.9584\n",
      "Epoch 256/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0038 - val_loss: 1.9588\n",
      "Epoch 257/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0038 - val_loss: 1.9604\n",
      "Epoch 258/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 1.9611\n",
      "Epoch 259/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0037 - val_loss: 1.9601\n",
      "Epoch 260/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 1.9600\n",
      "Epoch 261/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0036 - val_loss: 1.9607\n",
      "Epoch 262/600\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0036 - val_loss: 1.9623\n",
      "Epoch 263/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 1.9637\n",
      "Epoch 264/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0035 - val_loss: 1.9649\n",
      "Epoch 265/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 1.9655\n",
      "Epoch 266/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0034 - val_loss: 1.9656\n",
      "Epoch 267/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0034 - val_loss: 1.9656\n",
      "Epoch 268/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0033 - val_loss: 1.9664\n",
      "Epoch 269/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0033 - val_loss: 1.9682\n",
      "Epoch 270/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0033 - val_loss: 1.9698\n",
      "Epoch 271/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 1.9712\n",
      "Epoch 272/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 1.9724\n",
      "Epoch 273/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0032 - val_loss: 1.9736\n",
      "Epoch 274/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 1.9753\n",
      "Epoch 275/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0031 - val_loss: 1.9771\n",
      "Epoch 276/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0031 - val_loss: 1.9773\n",
      "Epoch 277/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 1.9779\n",
      "Epoch 278/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 1.9787\n",
      "Epoch 279/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0030 - val_loss: 1.9795\n",
      "Epoch 280/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 1.9797\n",
      "Epoch 281/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0029 - val_loss: 1.9797\n",
      "Epoch 282/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0029 - val_loss: 1.9801\n",
      "Epoch 283/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 1.9803\n",
      "Epoch 284/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 1.9806\n",
      "Epoch 285/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0028 - val_loss: 1.9810\n",
      "Epoch 286/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0027 - val_loss: 1.9812\n",
      "Epoch 287/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0027 - val_loss: 1.9819\n",
      "Epoch 288/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0027 - val_loss: 1.9829\n",
      "Epoch 289/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 1.9838\n",
      "Epoch 290/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 1.9841\n",
      "Epoch 291/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 1.9839\n",
      "Epoch 292/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0026 - val_loss: 1.9841\n",
      "Epoch 293/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 1.9845\n",
      "Epoch 294/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 1.9853\n",
      "Epoch 295/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 1.9861\n",
      "Epoch 296/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0025 - val_loss: 1.9868\n",
      "Epoch 297/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 1.9874\n",
      "Epoch 298/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0024 - val_loss: 1.9880\n",
      "Epoch 299/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 1.9884\n",
      "Epoch 300/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0024 - val_loss: 1.9885\n",
      "Epoch 301/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 1.9894\n",
      "Epoch 302/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 1.9907\n",
      "Epoch 303/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 1.9920\n",
      "Epoch 304/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0023 - val_loss: 1.9932\n",
      "Epoch 305/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 1.9932\n",
      "Epoch 306/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 1.9931\n",
      "Epoch 307/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 1.9939\n",
      "Epoch 308/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0022 - val_loss: 1.9952\n",
      "Epoch 309/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 1.9967\n",
      "Epoch 310/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 1.9980\n",
      "Epoch 311/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 1.9992\n",
      "Epoch 312/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0021 - val_loss: 2.0005\n",
      "Epoch 313/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0021 - val_loss: 2.0020\n",
      "Epoch 314/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 2.0039\n",
      "Epoch 315/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0020 - val_loss: 2.0052\n",
      "Epoch 316/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 2.0065\n",
      "Epoch 317/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 2.0068\n",
      "Epoch 318/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 2.0080\n",
      "Epoch 319/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0020 - val_loss: 2.0099\n",
      "Epoch 320/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 2.0124\n",
      "Epoch 321/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 2.0147\n",
      "Epoch 322/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 2.0158\n",
      "Epoch 323/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0019 - val_loss: 2.0166\n",
      "Epoch 324/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 2.0177\n",
      "Epoch 325/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0019 - val_loss: 2.0195\n",
      "Epoch 326/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 2.0219\n",
      "Epoch 327/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 2.0244\n",
      "Epoch 328/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 2.0269\n",
      "Epoch 329/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 2.0294\n",
      "Epoch 330/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 2.0308\n",
      "Epoch 331/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 2.0322\n",
      "Epoch 332/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0018 - val_loss: 2.0337\n",
      "Epoch 333/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 2.0357\n",
      "Epoch 334/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 2.0379\n",
      "Epoch 335/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 2.0403\n",
      "Epoch 336/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 2.0428\n",
      "Epoch 337/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 2.0444\n",
      "Epoch 338/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 2.0467\n",
      "Epoch 339/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0017 - val_loss: 2.0492\n",
      "Epoch 340/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 2.0515\n",
      "Epoch 341/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 2.0540\n",
      "Epoch 342/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 2.0567\n",
      "Epoch 343/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 2.0590\n",
      "Epoch 344/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 2.0608\n",
      "Epoch 345/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 2.0626\n",
      "Epoch 346/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0016 - val_loss: 2.0646\n",
      "Epoch 347/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0016 - val_loss: 2.0669\n",
      "Epoch 348/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 2.0694\n",
      "Epoch 349/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 2.0720\n",
      "Epoch 350/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 2.0744\n",
      "Epoch 351/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 2.0767\n",
      "Epoch 352/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 2.0781\n",
      "Epoch 353/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 2.0797\n",
      "Epoch 354/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 2.0818\n",
      "Epoch 355/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0015 - val_loss: 2.0839\n",
      "Epoch 356/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0015 - val_loss: 2.0865\n",
      "Epoch 357/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 2.0888\n",
      "Epoch 358/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 2.0910\n",
      "Epoch 359/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 2.0932\n",
      "Epoch 360/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 2.0947\n",
      "Epoch 361/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 2.0965\n",
      "Epoch 362/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 2.0985\n",
      "Epoch 363/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0014 - val_loss: 2.1008\n",
      "Epoch 364/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 2.1030\n",
      "Epoch 365/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0014 - val_loss: 2.1050\n",
      "Epoch 366/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0014 - val_loss: 2.1071\n",
      "Epoch 367/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 2.1093\n",
      "Epoch 368/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 2.1112\n",
      "Epoch 369/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 2.1131\n",
      "Epoch 370/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 2.1152\n",
      "Epoch 371/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 2.1171\n",
      "Epoch 372/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 2.1188\n",
      "Epoch 373/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 2.1207\n",
      "Epoch 374/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 2.1227\n",
      "Epoch 375/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0013 - val_loss: 2.1246\n",
      "Epoch 376/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 2.1269\n",
      "Epoch 377/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 2.1288\n",
      "Epoch 378/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0013 - val_loss: 2.1305\n",
      "Epoch 379/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 2.1325\n",
      "Epoch 380/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 2.1345\n",
      "Epoch 381/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0012 - val_loss: 2.1365\n",
      "Epoch 382/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 2.1384\n",
      "Epoch 383/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 2.1401\n",
      "Epoch 384/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 2.1420\n",
      "Epoch 385/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 2.1435\n",
      "Epoch 386/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 2.1455\n",
      "Epoch 387/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 2.1477\n",
      "Epoch 388/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 2.1499\n",
      "Epoch 389/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 2.1519\n",
      "Epoch 390/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0012 - val_loss: 2.1536\n",
      "Epoch 391/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0012 - val_loss: 2.1555\n",
      "Epoch 392/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 2.1574\n",
      "Epoch 393/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 2.1593\n",
      "Epoch 394/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 2.1607\n",
      "Epoch 395/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 2.1622\n",
      "Epoch 396/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 2.1640\n",
      "Epoch 397/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 2.1661\n",
      "Epoch 398/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 2.1681\n",
      "Epoch 399/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 2.1697\n",
      "Epoch 400/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 2.1715\n",
      "Epoch 401/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0011 - val_loss: 2.1733\n",
      "Epoch 402/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 2.1752\n",
      "Epoch 403/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 2.1772\n",
      "Epoch 404/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 2.1794\n",
      "Epoch 405/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 2.1807\n",
      "Epoch 406/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0011 - val_loss: 2.1821\n",
      "Epoch 407/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 2.1838\n",
      "Epoch 408/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 2.1857\n",
      "Epoch 409/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 2.1877\n",
      "Epoch 410/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 2.1896\n",
      "Epoch 411/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 2.1909\n",
      "Epoch 412/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 2.1924\n",
      "Epoch 413/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0010 - val_loss: 2.1939\n",
      "Epoch 414/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0010 - val_loss: 2.1949\n",
      "Epoch 415/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.9680e-04 - val_loss: 2.1961\n",
      "Epoch 416/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.9115e-04 - val_loss: 2.1976\n",
      "Epoch 417/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.8551e-04 - val_loss: 2.1990\n",
      "Epoch 418/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.7988e-04 - val_loss: 2.2006\n",
      "Epoch 419/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.7436e-04 - val_loss: 2.2022\n",
      "Epoch 420/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.6885e-04 - val_loss: 2.2033\n",
      "Epoch 421/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.6323e-04 - val_loss: 2.2043\n",
      "Epoch 422/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.5757e-04 - val_loss: 2.2055\n",
      "Epoch 423/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.5194e-04 - val_loss: 2.2068\n",
      "Epoch 424/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.4634e-04 - val_loss: 2.2074\n",
      "Epoch 425/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.4070e-04 - val_loss: 2.2079\n",
      "Epoch 426/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.3502e-04 - val_loss: 2.2085\n",
      "Epoch 427/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.2941e-04 - val_loss: 2.2091\n",
      "Epoch 428/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.2382e-04 - val_loss: 2.2097\n",
      "Epoch 429/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.1826e-04 - val_loss: 2.2102\n",
      "Epoch 430/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.1282e-04 - val_loss: 2.2105\n",
      "Epoch 431/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.0742e-04 - val_loss: 2.2104\n",
      "Epoch 432/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.0204e-04 - val_loss: 2.2106\n",
      "Epoch 433/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.9672e-04 - val_loss: 2.2109\n",
      "Epoch 434/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.9140e-04 - val_loss: 2.2112\n",
      "Epoch 435/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.8613e-04 - val_loss: 2.2116\n",
      "Epoch 436/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.8094e-04 - val_loss: 2.2122\n",
      "Epoch 437/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.7577e-04 - val_loss: 2.2129\n",
      "Epoch 438/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.7062e-04 - val_loss: 2.2136\n",
      "Epoch 439/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.6548e-04 - val_loss: 2.2143\n",
      "Epoch 440/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.6046e-04 - val_loss: 2.2150\n",
      "Epoch 441/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.5548e-04 - val_loss: 2.2154\n",
      "Epoch 442/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.5042e-04 - val_loss: 2.2161\n",
      "Epoch 443/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.4548e-04 - val_loss: 2.2170\n",
      "Epoch 444/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.4061e-04 - val_loss: 2.2178\n",
      "Epoch 445/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.3574e-04 - val_loss: 2.2185\n",
      "Epoch 446/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.3089e-04 - val_loss: 2.2194\n",
      "Epoch 447/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.2617e-04 - val_loss: 2.2201\n",
      "Epoch 448/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.2141e-04 - val_loss: 2.2209\n",
      "Epoch 449/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1676e-04 - val_loss: 2.2217\n",
      "Epoch 450/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1209e-04 - val_loss: 2.2224\n",
      "Epoch 451/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.0745e-04 - val_loss: 2.2231\n",
      "Epoch 452/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.0290e-04 - val_loss: 2.2240\n",
      "Epoch 453/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.9836e-04 - val_loss: 2.2251\n",
      "Epoch 454/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.9387e-04 - val_loss: 2.2263\n",
      "Epoch 455/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.8944e-04 - val_loss: 2.2274\n",
      "Epoch 456/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.8505e-04 - val_loss: 2.2280\n",
      "Epoch 457/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.8063e-04 - val_loss: 2.2287\n",
      "Epoch 458/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7632e-04 - val_loss: 2.2297\n",
      "Epoch 459/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7201e-04 - val_loss: 2.2309\n",
      "Epoch 460/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.6774e-04 - val_loss: 2.2320\n",
      "Epoch 461/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.6352e-04 - val_loss: 2.2330\n",
      "Epoch 462/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.5932e-04 - val_loss: 2.2338\n",
      "Epoch 463/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.5520e-04 - val_loss: 2.2347\n",
      "Epoch 464/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.5111e-04 - val_loss: 2.2358\n",
      "Epoch 465/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.4701e-04 - val_loss: 2.2369\n",
      "Epoch 466/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.4299e-04 - val_loss: 2.2382\n",
      "Epoch 467/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.3896e-04 - val_loss: 2.2396\n",
      "Epoch 468/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.3499e-04 - val_loss: 2.2407\n",
      "Epoch 469/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.3107e-04 - val_loss: 2.2415\n",
      "Epoch 470/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.2716e-04 - val_loss: 2.2423\n",
      "Epoch 471/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.2328e-04 - val_loss: 2.2433\n",
      "Epoch 472/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1942e-04 - val_loss: 2.2445\n",
      "Epoch 473/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1563e-04 - val_loss: 2.2458\n",
      "Epoch 474/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1187e-04 - val_loss: 2.2470\n",
      "Epoch 475/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.0815e-04 - val_loss: 2.2481\n",
      "Epoch 476/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0438e-04 - val_loss: 2.2493\n",
      "Epoch 477/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0071e-04 - val_loss: 2.2502\n",
      "Epoch 478/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9707e-04 - val_loss: 2.2512\n",
      "Epoch 479/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.9345e-04 - val_loss: 2.2523\n",
      "Epoch 480/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8983e-04 - val_loss: 2.2535\n",
      "Epoch 481/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8627e-04 - val_loss: 2.2548\n",
      "Epoch 482/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8273e-04 - val_loss: 2.2563\n",
      "Epoch 483/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7923e-04 - val_loss: 2.2576\n",
      "Epoch 484/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7579e-04 - val_loss: 2.2583\n",
      "Epoch 485/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7231e-04 - val_loss: 2.2593\n",
      "Epoch 486/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6889e-04 - val_loss: 2.2604\n",
      "Epoch 487/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6549e-04 - val_loss: 2.2616\n",
      "Epoch 488/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.6212e-04 - val_loss: 2.2630\n",
      "Epoch 489/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5879e-04 - val_loss: 2.2642\n",
      "Epoch 490/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5548e-04 - val_loss: 2.2650\n",
      "Epoch 491/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5217e-04 - val_loss: 2.2659\n",
      "Epoch 492/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4894e-04 - val_loss: 2.2671\n",
      "Epoch 493/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4573e-04 - val_loss: 2.2683\n",
      "Epoch 494/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4250e-04 - val_loss: 2.2696\n",
      "Epoch 495/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.3930e-04 - val_loss: 2.2711\n",
      "Epoch 496/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.3615e-04 - val_loss: 2.2724\n",
      "Epoch 497/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.3303e-04 - val_loss: 2.2730\n",
      "Epoch 498/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.2993e-04 - val_loss: 2.2739\n",
      "Epoch 499/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.2686e-04 - val_loss: 2.2749\n",
      "Epoch 500/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.2379e-04 - val_loss: 2.2760\n",
      "Epoch 501/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.2075e-04 - val_loss: 2.2770\n",
      "Epoch 502/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.1772e-04 - val_loss: 2.2779\n",
      "Epoch 503/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.1476e-04 - val_loss: 2.2788\n",
      "Epoch 504/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.1182e-04 - val_loss: 2.2800\n",
      "Epoch 505/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.0887e-04 - val_loss: 2.2811\n",
      "Epoch 506/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.0594e-04 - val_loss: 2.2822\n",
      "Epoch 507/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.0302e-04 - val_loss: 2.2832\n",
      "Epoch 508/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.0016e-04 - val_loss: 2.2844\n",
      "Epoch 509/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.9734e-04 - val_loss: 2.2856\n",
      "Epoch 510/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.9451e-04 - val_loss: 2.2865\n",
      "Epoch 511/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.9169e-04 - val_loss: 2.2872\n",
      "Epoch 512/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.8892e-04 - val_loss: 2.2881\n",
      "Epoch 513/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.8616e-04 - val_loss: 2.2890\n",
      "Epoch 514/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.8341e-04 - val_loss: 2.2900\n",
      "Epoch 515/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.8068e-04 - val_loss: 2.2911\n",
      "Epoch 516/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.7797e-04 - val_loss: 2.2924\n",
      "Epoch 517/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.7530e-04 - val_loss: 2.2936\n",
      "Epoch 518/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.7262e-04 - val_loss: 2.2947\n",
      "Epoch 519/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.6998e-04 - val_loss: 2.2954\n",
      "Epoch 520/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.6733e-04 - val_loss: 2.2960\n",
      "Epoch 521/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.6476e-04 - val_loss: 2.2969\n",
      "Epoch 522/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.6219e-04 - val_loss: 2.2979\n",
      "Epoch 523/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.5960e-04 - val_loss: 2.2992\n",
      "Epoch 524/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.5703e-04 - val_loss: 2.3003\n",
      "Epoch 525/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.5454e-04 - val_loss: 2.3011\n",
      "Epoch 526/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.5204e-04 - val_loss: 2.3017\n",
      "Epoch 527/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.4953e-04 - val_loss: 2.3023\n",
      "Epoch 528/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.4706e-04 - val_loss: 2.3030\n",
      "Epoch 529/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.4458e-04 - val_loss: 2.3039\n",
      "Epoch 530/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.4212e-04 - val_loss: 2.3048\n",
      "Epoch 531/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.3971e-04 - val_loss: 2.3057\n",
      "Epoch 532/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.3733e-04 - val_loss: 2.3067\n",
      "Epoch 533/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.3499e-04 - val_loss: 2.3074\n",
      "Epoch 534/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.3264e-04 - val_loss: 2.3082\n",
      "Epoch 535/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.3028e-04 - val_loss: 2.3093\n",
      "Epoch 536/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.2795e-04 - val_loss: 2.3105\n",
      "Epoch 537/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.2562e-04 - val_loss: 2.3115\n",
      "Epoch 538/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.2333e-04 - val_loss: 2.3125\n",
      "Epoch 539/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.2107e-04 - val_loss: 2.3130\n",
      "Epoch 540/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.1881e-04 - val_loss: 2.3135\n",
      "Epoch 541/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.1658e-04 - val_loss: 2.3142\n",
      "Epoch 542/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.1435e-04 - val_loss: 2.3150\n",
      "Epoch 543/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.1211e-04 - val_loss: 2.3160\n",
      "Epoch 544/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.0992e-04 - val_loss: 2.3172\n",
      "Epoch 545/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.0774e-04 - val_loss: 2.3184\n",
      "Epoch 546/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.0560e-04 - val_loss: 2.3189\n",
      "Epoch 547/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.0341e-04 - val_loss: 2.3196\n",
      "Epoch 548/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.0127e-04 - val_loss: 2.3204\n",
      "Epoch 549/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.9914e-04 - val_loss: 2.3215\n",
      "Epoch 550/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.9702e-04 - val_loss: 2.3226\n",
      "Epoch 551/600\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.9495e-04 - val_loss: 2.3232\n",
      "Epoch 552/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.9284e-04 - val_loss: 2.3239\n",
      "Epoch 553/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.9076e-04 - val_loss: 2.3250\n",
      "Epoch 554/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.8869e-04 - val_loss: 2.3258\n",
      "Epoch 555/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.8665e-04 - val_loss: 2.3265\n",
      "Epoch 556/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.8463e-04 - val_loss: 2.3275\n",
      "Epoch 557/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.8263e-04 - val_loss: 2.3283\n",
      "Epoch 558/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.8062e-04 - val_loss: 2.3293\n",
      "Epoch 559/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.7863e-04 - val_loss: 2.3301\n",
      "Epoch 560/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.7664e-04 - val_loss: 2.3312\n",
      "Epoch 561/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.7467e-04 - val_loss: 2.3321\n",
      "Epoch 562/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.7274e-04 - val_loss: 2.3325\n",
      "Epoch 563/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.7080e-04 - val_loss: 2.3332\n",
      "Epoch 564/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.6886e-04 - val_loss: 2.3341\n",
      "Epoch 565/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.6696e-04 - val_loss: 2.3350\n",
      "Epoch 566/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.6504e-04 - val_loss: 2.3359\n",
      "Epoch 567/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.6315e-04 - val_loss: 2.3370\n",
      "Epoch 568/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.6127e-04 - val_loss: 2.3381\n",
      "Epoch 569/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.5942e-04 - val_loss: 2.3390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 570/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.5757e-04 - val_loss: 2.3394\n",
      "Epoch 571/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.5571e-04 - val_loss: 2.3401\n",
      "Epoch 572/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.5391e-04 - val_loss: 2.3409\n",
      "Epoch 573/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.5209e-04 - val_loss: 2.3419\n",
      "Epoch 574/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.5027e-04 - val_loss: 2.3430\n",
      "Epoch 575/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.4847e-04 - val_loss: 2.3439\n",
      "Epoch 576/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.4669e-04 - val_loss: 2.3447\n",
      "Epoch 577/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.4490e-04 - val_loss: 2.3454\n",
      "Epoch 578/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.4315e-04 - val_loss: 2.3463\n",
      "Epoch 579/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.4141e-04 - val_loss: 2.3471\n",
      "Epoch 580/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.3967e-04 - val_loss: 2.3481\n",
      "Epoch 581/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.3792e-04 - val_loss: 2.3491\n",
      "Epoch 582/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.3620e-04 - val_loss: 2.3499\n",
      "Epoch 583/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.3451e-04 - val_loss: 2.3507\n",
      "Epoch 584/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.3281e-04 - val_loss: 2.3514\n",
      "Epoch 585/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.3111e-04 - val_loss: 2.3523\n",
      "Epoch 586/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.2942e-04 - val_loss: 2.3533\n",
      "Epoch 587/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.2777e-04 - val_loss: 2.3541\n",
      "Epoch 588/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.2611e-04 - val_loss: 2.3550\n",
      "Epoch 589/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.2446e-04 - val_loss: 2.3561\n",
      "Epoch 590/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.2281e-04 - val_loss: 2.3569\n",
      "Epoch 591/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.2116e-04 - val_loss: 2.3576\n",
      "Epoch 592/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.1954e-04 - val_loss: 2.3584\n",
      "Epoch 593/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.1794e-04 - val_loss: 2.3593\n",
      "Epoch 594/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.1634e-04 - val_loss: 2.3604\n",
      "Epoch 595/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.1474e-04 - val_loss: 2.3615\n",
      "Epoch 596/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.1318e-04 - val_loss: 2.3620\n",
      "Epoch 597/600\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.1159e-04 - val_loss: 2.3625\n",
      "Epoch 598/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.1004e-04 - val_loss: 2.3634\n",
      "Epoch 599/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.0847e-04 - val_loss: 2.3645\n",
      "Epoch 600/600\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.0692e-04 - val_loss: 2.3655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xf9aef43d08>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = X_train, y = y_train, epochs = 600, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xf9b526fc88>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU1d3H8c9vkpAgYQlhXwPKLsoSF6yiguKGuKACLnW3rXUpz1Ortm61drW11UeLWxWpKyq1VHGlKu6SsO+bCAlLFiCEJeuc5487SIgJmcCEOzP5vl+vec3MvXdmfieE79yce+495pxDRERiX8DvAkREJDIU6CIicUKBLiISJxToIiJxQoEuIhInEv364DZt2riMjAy/Pl5EJCZlZ2cXOOfa1rTOt0DPyMggKyvLr48XEYlJZvZtbevU5SIiEicU6CIicUKBLiISJ3zrQ69JeXk5OTk5lJSU+F1KVEtJSaFLly4kJSX5XYqIRJGoCvScnByaN29ORkYGZuZ3OVHJOUdhYSE5OTn06NHD73JEJIpEVZdLSUkJ6enpCvP9MDPS09P1V4yIfE9UBTqgMA+DfkYiUpOo6nIREYlLpcWwZQ0UrvbuOw+Bw0dE/GMU6NWkpqayY8cOv8sQkVhTPbT33ApXw868fbc9caICXUTEV/UJ7dQOkH449D4DWvf0Hrfu6d2aNGuQ8hTotXDO8Ytf/IK3334bM+Ouu+5i3LhxbNy4kXHjxrF9+3YqKiqYNGkSJ5xwAtdeey1ZWVmYGddccw0TJ070uwkiciCiPLT3J2oD/df/WcySDdsj+p79O7Xg3nMHhLXttGnTmDdvHvPnz6egoIBjjjmG4cOH8+KLL3LGGWfwq1/9isrKSnbt2sW8efPIzc1l0aJFAGzbti2idYtIhMVwaO9P1Aa63z799FMmTJhAQkIC7du35+STT2b27Nkcc8wxXHPNNZSXl3P++eczaNAgevbsyZo1a7j55ps555xzGDVqlN/li0ichvb+RG2gh7sn3VBqmzx7+PDhzJo1i7feeosrrriC2267jR/+8IfMnz+fd999l8cee4ypU6fyzDPPHOKKRRqpXVsgbynkLfHu85dB4SrYsXnf7eIktPcnagPdb8OHD+eJJ57gyiuvZMuWLcyaNYsHH3yQb7/9ls6dO3P99dezc+dO5syZw9lnn02TJk0YO3Yshx9+OFdddZXf5YvEn9IdkL98b3Dvud+xae82yS2hXV844nRI7wmtD98b3HES2vujQK/FBRdcwBdffMHRRx+NmfGnP/2JDh068Nxzz/Hggw+SlJREamoqU6ZMITc3l6uvvppgMAjA73//e5+rF4lhFaVQsHLf0M5bAtuqXAY8sSm07eMN/WvXD9r19+5bdIJGfOKd1da10NAyMzNd9Qkuli5dSr9+/XypJ9boZyUxzznYvgE2LYTNC2HTIi+8C1eBq/S2CSRCeq99Q7tdP0jLgECCr+X7xcyynXOZNa3THrqINLyK0r3dJZsW7r3t3rJ3m7QMaDcA+p27N8DTj4DEJr6VHWsU6CISOZXlsOUbKFjuHZzcvMQL8YKVe/e6E5KhfX/oNxo6HAUdBnrhndLC39rjgAJdRMLnHOzeCkXrYdv6vffbvvVCe8tqCFbs3b5VN2h/JPQd7YV4uwHeXneCoqch6KcqIhCshO253hjtovWwexuUbPPud2/1bsWbvHVl1a51lNjUC+42vaDvOd7Byja9vVtyqj/taaQU6CKNUVEu5HwN62fD+q+8/uzK0n23sQRo2gpSWkHTNG/oX8+ToWVXaNU1dN8NDktv1CNLookCXaQxqCiDdZ/Divdg5bveSBKAxBToNBiOvd7rCkk/3Ds42bS1N25bQR1TFOgi8ap4E6x8D1a8C2s+8rpKEpIh40TIvBa6HQftB2oUSRxRoB+E/V07fe3atYwePfq7C3aJNDjnYMNcWP62txe+cb63vEVnGHixd8p7j+GN4ozJxkqBLhLLKspg7SewfIYX5NtzwQLQ9TgYea8X4u36q+ukkYjeQH/7Du9ATSR1GAhn/aHW1bfffjvdu3fnxhtvBOC+++7DzJg1axZbt26lvLycBx54gPPOO69eH1tSUsJPfvITsrKySExM5KGHHuLUU09l8eLFXH311ZSVlREMBnn99dfp1KkTl1xyCTk5OVRWVnL33Xczbty4g2q2xJmSIlj5Pix7C1Z9AKXbIekw7zT4EXd7IX5Ya7+rFB9Eb6D7YPz48fzsZz/7LtCnTp3KO++8w8SJE2nRogUFBQUcf/zxjBkzpl4TNT/22GMALFy4kGXLljFq1ChWrFjB448/zq233spll11GWVkZlZWVzJgxg06dOvHWW28BUFRUFPmGSuwpyvH2wJe95e2RByugWVsYcD70OccbfZLU1O8qxWfRG+j72ZNuKIMHDyYvL48NGzaQn59PWloaHTt2ZOLEicyaNYtAIEBubi6bN2+mQ4cOYb/vp59+ys033wxA37596d69OytWrGDYsGH89re/JScnhwsvvJBevXoxcOBAfv7zn3P77bczevRoTjrppIZqrkS7wtWwaBos+8/e/vD0XjDsp16Id8lstNczkZpFb6D75KKLLuK1115j06ZNjB8/nhdeeIH8/Hyys7NJSkoiIyODkpKSer1nbRdAu/TSSznuuON46623OOOMM3j66acZMWIE2dnZzJgxgzvvvJNRo0Zxzz33RKJpEgu2rYfF/4JFr8PGed6yLsfCafd5Id62t5/VSZRToFczfvx4rr/+egoKCvj444+ZOnUq7dq1IykpiQ8//JBvv/227jepZvjw4bzwwguMGDGCFStWsG7dOvr06cOaNWvo2bMnt9xyC2vWrGHBggX07duX1q1bc/nll5OamsrkyZMj30iJLsWbYcm/vRBf/6W3rNMQGPVbr0ulZRd/65OYoUCvZsCAARQXF9O5c2c6duzIZZddxrnnnktmZiaDBg2ib9++9X7PG2+8kR//+McMHDiQxMREJk+eTHJyMq+88grPP/88SUlJdOjQgXvuuYfZs2dz2223EQgESEpKYtKkSQ3QSvHd1rXenviqmfDtZ+CC3nVORtwNR17onZUpUk+6HnqM0s8qBu3eBsvehIWveif6gBfifc+GI8d6l4wVqYOuhy7il2AlrP4vzJkCK96ByjJo1R1O+SUMutS7JopIhCjQD9LChQu54oor9lmWnJzMV1995VNFEhW2rIG5L8C8F6F4g3cBq8xrvTM2Ow/RiT7SIKIu0J1z9Rrj7beBAwcyb968Q/qZfnWTSR0KV8PiabBkOmxa4J2xecRp3hDc3mfpminS4OoMdDPrCkwBOgBB4Enn3MPVtjHgYeBsYBdwlXNuTn2LSUlJobCwkPT09JgK9UPJOUdhYSEpKSl+lyKlO2DdF5Cb7V0Aa0PoV77r8XD6b7x+8Zad/a1RGpVw9tArgP91zs0xs+ZAtpm975xbUmWbs4BeodtxwKTQfb106dKFnJwc8vPz6/vSRiUlJYUuXTSU7ZDbWegNK1z3Baz7EjbMg2A5YNDx6FCIX6hhhuKbOgPdObcR2Bh6XGxmS4HOQNVAPw+Y4ry+gC/NrJWZdQy9NmxJSUn06NGjPi8RibyynaF5MVfAjjzIW+wFeMEKb31CE+g8FE64CXqc7J2xmdzc35pFqGcfupllAIOB6kf8OgPrqzzPCS3bJ9DN7AbgBoBu3brVr1KRA7V7mzffZck2KC32Aru02DtYuSPfm6lnZwEUb4TtG6F8576vT2npdaMcPQG6nwAdB0GSurwk+oQd6GaWCrwO/Mw5t7366hpe8r0jd865J4EnwRuHXo86RepWUuSFd+FKWPuZ16edv9wL6pokJENqe+9g5WHp3mTGvUZBajtvaGGbXtC8ozd7TyBwaNsicgDCCnQzS8IL8xecc9Nq2CQHqDqgtguw4eDLEwkJBr096s2LIX+Zt5e9bR2U7/IOTm5eBDs2793eEqDDkdDzFG/S4rZ9vasTNmkWuqV6c2UqqCWOhDPKxYB/AEudcw/Vstl04CYzexnvYGhRffvPRfYRDHpzYC5/2zv4uHHe92ebT20PyS287o/DR0K7vt6edotO3gWtNOO8NDLh7KH/ALgCWGhmewZc/xLoBuCcexyYgTdkcRXesMWrI1+qxL3yEu/U+PkveUMBd2/1ukU6HOn1X7fvD236eM+bNNfetUg14Yxy+ZSa+8irbuOAn0aqKGlkNi2C7MmwcKrXD96yG/QbAxknedc50RyYImGJujNFpZHYtcXbG5/7gje2OyEZ+o+BQZd5QwG19y1Sbwp0ObR25MOHD8Ccf4Kr9C4TO+oBL8g1D6bIQVGgS8PbWeB1qXz9pDcSxQJwzHXe1QY7DtKFqkQiRIEuDcM57+zKrH94s/FUlnkXqsq4EXqf6Y1IEZGIUqBLZJUUwYKpkPUM5C3xhhUOvRoyr1GIizQwBbpERjAI2c/C+/d448U7DoIx/+ddcVCjVEQOCQW6HJzSYu8A51eTvDM3ewz3ZqjvPNTvykQaHQW6HJicbPjy77DkDQhWQPcTvSAfcKEOcor4RIEu4asog6XT4avHIWe2d7bmMdfBgAug2/F+VyfS6CnQpW7BSm+kysz7Yes33tjxM//oDTtMaeF3dSISokCX2lWUwYJX4NO/wpbV0KY3THgZep2hMzlFopACXb4vGIQ5k2HWX2B7DnQ4Ci6ZAn1HQyDB7+pEpBYKdNlr82Jv/HjObNg435ul59yH4YiROtApEgMU6OKd1Tn/ZXhzondafptecP4k75K1CnKRmKFAb+x2bYF//QhWvgfdhsHFz0Hz9n5XJSIHQIHeWAWDsOh1+OA+74JZZ/7RG4KYoF8JkVil/72N0bov4d1ferMCdTgKxk3RmZ0icUCB3pgU5XpBvuQNbzb78yfBUeM1BFEkTijQG4uNC+DFS7yrIZ5yJ5xwsy6aJRJnFOjxzjn45C/w0e/hsDZw3UxvsmURiTsK9HhWXgLTb4KFr3qXsT37z5rmTSSOKdDj0fYN8M4dsO4r2LEJRt4DJ/6PxpSLxDkFerzZ8g1MOQ92FUKvUTDkCjh8hN9VicghoECPJ6tmwuvXeo+vnK6hiCKNjMarxYOKUvjsYXhxHDTv5B34VJiLNDraQ491pTvgudGwYa53NcTz/w4pLf2uSkR8oECPZRvmwlv/610Z8cKnYODFOvAp0ogp0GPVvJfgP7dASisY+w848kK/KxIRnynQY01JEXz4O29ez4yTvIknNLZcRFCgx5ZdW+Dp07zp4I69Ac74HSQk+V2ViEQJBXqsqCiFly+Fohy48j/QY7jfFYlIlFGgx4LKcm8SinVfwEXPKsxFpEZ1jkM3s2fMLM/MFtWy/hQzKzKzeaHbPZEvsxHb8g08NwYW/wtGPaCDnyJSq3D20CcDjwJT9rPNJ8650RGpSPbKXwGTz4bKMu/a5YMu9bsiEYlidQa6c26WmWU0fCmyj2AQpt8MwUq49gNo29vvikQkykXq1P9hZjbfzN42swERes/Gbd4LsP5LGPUbhbmIhCUSB0XnAN2dczvM7GzgDaBXTRua2Q3ADQDdunWLwEfHqfzl8N6voNswOFrdLCISnoPeQ3fObXfO7Qg9ngEkmVmbWrZ90jmX6ZzLbNu27cF+dHzavRVeGg8JyXDBE5rvU0TCdtBpYWYdzLwLiJjZsaH3LDzY922Uykvg1atg23oY9zykdfe7IhGJIXV2uZjZS8ApQBszywHuBZIAnHOPAxcBPzGzCmA3MN455xqs4ni1bR3880IoXOmNaOl2nN8ViUiMCWeUy4Q61j+KN6xRDlQwCNN+BDvy4PJpcMRIvysSkRikM0WjwddPwLrPYcyjCnMROWA64ua3lR/Au7+C3mfB4Mv9rkZEYpgC3U+bFnoHQdv3h7FPa3IKETkoCnS/fPMJPHsOJDeHCa9AcqrfFYlIjFOg+2Hha/D8hdCiI1z7HrTs7HdFIhIHFOiH2pwp8Pq10OUYuOYdaNXV74pEJE5olMuhVLgaZvwCep4Cl06FxGS/KxKROKJAPxS2rYMvJ8HS/0BCE+/EIYW5iESYAr2h7SyAp0ZCyTboMBAuegZadPK7KhGJQwr0hhKshLKd8OlfYWc+/Ohj6Hi031WJSBxToDeE/BXwymVQsMJ7PvgKhbmINDgFeiSVFMGHv4O5z0NiCpz4P9748uNv9LsyEWkEFOiRUrYLnh8LuXNgwAVw2n0akigih5QCPRKCQXjxEsiZDRc9C0de6HdFItII6cSiSPjqcVj7CZz7sMJcRHyjPfSD9eHv4eM/eldLHHKl39WISCOmPfSDMfcF+PgP0PccuPAJXS1RRHylPfQDUVEK02+GBa9At2Fw8WRISPK7KhFp5BTo9VFZAd98DF88Bqtnwsm3e0MTFeYiEgUU6OEo3w15S2Dm/bDmI7AAnPsIDFWfuYhEDwV6XXZvg6dOhS1rIJAE5/wF+p0HqW39rkxEZB8K9Lp8OQm2fANnPQi9z4C07n5XJCJSIwX6/lRWwNx/wuEj4Lgb/K5GRGS/NGxxf1a+C9tzYehVflciIlInBXptNi6A9++BtB7Q5yy/qxERqZO6XGoy8zfwyZ8hIRkuf03DEkUkJijQqytcDZ/8BQZeAqMegObt/a5IRCQsCvTqPvubN9/nGb+F1HZ+VyMiEjb1oVe1fQPMewkGX64wF5GYo0Cv6ovHwAXhhJv9rkREpN7U5QKw/mtY9hbM/gccORbSMvyuSESk3hToxZtg8mioLIWWXeH0+/2uSETkgCjQsydDZRlcNxM6DPQOiIqIxKA6+9DN7BkzyzOzRbWsNzN7xMxWmdkCMxsS+TIbiHOwaBpknAhdMhXmIhLTwjkoOhk4cz/rzwJ6hW43AJMOvqxDZP1XULDc6zcXEYlxdQa6c24WsGU/m5wHTHGeL4FWZtYxUgU2GOfgg19D09Zw1CV+VyMictAiMWyxM7C+yvOc0LLvMbMbzCzLzLLy8/Mj8NEHYcErsO5zOP3X0KSZv7WIiERAJAK9ppmRXU0bOueedM5lOucy27b1cYKIijL472+h02AYdLl/dYiIRFAkAj0H6FrleRdgQwTet+HM/ScUrYMRd0FA51aJSHyIRJpNB34YGu1yPFDknNsYgfdtGMFK+PwR6JwJh4/0uxoRkYipcxy6mb0EnAK0MbMc4F4gCcA59zgwAzgbWAXsAq5uqGK/xznYOA9SWkLrnuG9Zsm/Yeta70qKVlNvkYhIbKoz0J1zE+pY74CfRqyiuhTlwtdPwCm/hHfugOxnveUn3wGn3rn/1+7aAu/+Etr2hT5nN3ytIiKHUOydKZqbDZ897N0AjvuxF9Qf/wHa9YMB5++7ffZzMOvP0K4vFG+EnQUw4WUIJBz62kVEGlDsBXq/c73JJ/KWwCl3eM8ryqBwFcz4ORwxEpKbe9sWrPSWtewK+cuhbCeMfRo6DfK3DSIiDSD2At0Mxj6177LEJnDOn+GpEd6e+4i7vP71NydCYlO4+m3NPCQicS9+xux1Huqdwv/5o1CU4w1NXPuJd+KQwlxEGoHY20Pfn5H3wvJ34NmzoHgzdP8BDLnS76pERA6J+NlDB0jrDpdMgeSWXl/6JVN04pCINBrxtYcO0Os07yYi0sho91VEJE4o0EVE4oQCXUQkTijQRUTihAJdRCROxFygL95QxL3/XsT2knK/SxERiSoxF+ibt5fw3BffsmJTsd+liIhElZgL9N7tvQtvLd+sQBcRqSrmAr1zq6akJieyXHvoIiL7iLlANzN6t09VoIuIVBNzgQ7Qp0Nzlm8uxpssSUREIFYDvX1ztu0qJ6+41O9SRESiRkwGev9OLQFYmFPkcyUiItEjJgP9qC4tSQwY2eu2+l2KiEjUiMlAT0lKYEDnlmR/q0AXEdkjJgMdYEi3VizI2UZ5ZdDvUkREokLMBvrQ7mmUlAdZmKt+dBERiOFA/8HhbQgYfLQ83+9SRESiQswGelqzJgzulsZHy/P8LkVEJCrEbKADnNqnLQtyisjXeHQRkdgO9FP6tAPQXrqICDEe6AM6taBd82RmLlWgi4jEdKCbGWcd2YH/Lstj264yv8sREfFVTAc6wMWZXSmrDDJ9/ga/SxER8VXMB/qRnVvSr2MLXs3K8bsUERFfxXygA1w8tAsLc4tYtmm736WIiPgmrEA3szPNbLmZrTKzO2pYf5WZ5ZvZvNDtusiXWrvzB3cmKcGYOlt76SLSeNUZ6GaWADwGnAX0ByaYWf8aNn3FOTcodHs6wnXuV+tmTRg1oAOvZa9nZ2nFofxoEZGoEc4e+rHAKufcGudcGfAycF7DllV/157Yg+0lFUzNWu93KSIivggn0DsDVVMyJ7SsurFmtsDMXjOzrjW9kZndYGZZZpaVnx/Za7AM6ZZGZvc0/vHpN1ToCowi0giFE+hWw7Lqk3n+B8hwzh0FfAA8V9MbOeeedM5lOucy27ZtW79Kw3DdST3J2bqbNxdsjPh7i4hEu3ACPQeousfdBdhn0LdzrtA5t+eCKk8BQyNTXv2M6t+efh1b8NcPVug66SLS6IQT6LOBXmbWw8yaAOOB6VU3MLOOVZ6OAZZGrsTwBQLGbWf05tvCXTz3+Vo/ShAR8U2dge6cqwBuAt7FC+qpzrnFZna/mY0JbXaLmS02s/nALcBVDVVwXU7t045T+7TlofdXkLttt19liIgccuZc9e7wQyMzM9NlZWU1yHvnbN3FaQ99zIi+7fj7Zb70/oiINAgzy3bOZda0Li7OFK2uS9ph3HjKEcxYuInPVhX4XY6IyCERl4EOcMPwnnRt3ZT7pi/WAVIRaRTiNtBTkhK4+5z+rMzbweMfrfa7HBGRBhe3gQ5wev/2jDm6E3+buZI567b6XY6ISIOK60A3Mx644Eg6tkzh1pfnUlxS7ndJIiINJq4DHaBFShIPjx9E7tbd3PvvxX6XIyLSYOI+0AGGdm/NLSN7MW1uLm/MzfW7HBGRBtEoAh3gplOPILN7Gne9sYh1hbv8LkdEJOIaTaAnJgT42/hBBAyumzJb/ekiEncaTaCDd8LRpMuHsjp/J7e8NJfKoD9nyYqINIRGFegAPziiDfefN4APl+dz1xuL8OvSByIikZbodwF+uOy47uRu3c3fP1pN85RE7jyrL2Y1XfZdRCR2NMpAB7jtjD7sKK3gyVlraJ6cyM0je/ldkojIQWm0gW5m3HfuAHaUVvCX91fQLDmRa07s4XdZIiIHrNEGOngTYvxp7FHsKq3k/jeXkJQY4Irju/tdlojIAWl0B0WrS0wI8PCEQYzs246731jEX95brgOlIhKTGn2gAyQnJvDEFUMZl9mV//vvKn7+6gJKKyr9LktEpF4adZdLVYkJAf4wdiCdWjXlrx+sYP2WXUy6fAjpqcl+lyYiEhbtoVdhZtx6Wi8emTCY+TnbOO+xz1i2abvfZYmIhEWBXoMxR3di6o+GUVYRZOzfP+fdxZv8LklEpE4K9Foc3bUV0286kSPapfKjf2bzuxlLKavQVHYiEr0U6PvRoWUKU388jCuO786Ts9Zw3mOfsXSjumBEJDop0OuQnJjAb84/kqd+mEl+cSljHv2Uv3+0ShNPi0jUUaCH6fT+7Xlv4nBO79+eP72znNGPfMoXqwv9LktE5DsK9Hpo3awJj106hCevGMrOsgomPPUlN780l01FJX6XJiKicej1ZWaMGtCB4b3bMumj1Uz6eDUfLNnM9cN78qPhPWmWrB+piPhDe+gHKCUpgYmn92bm/5zMyH7teGTmSk5+8CNe+nodFepfFxEfKNAPUtfWh/HopUOYduMJZKQfxp3TFnL2I5/w4fI8XRNGRA4pBXqEDOmWxqs/Hsaky4ZQWhHk6mdnc+6jnzJtTo7Gr4vIIWF+7UVmZma6rKwsXz67oZVVBHktO4dnPvuGVXk7SG/WhDGDOjF2SBcGdGqh2ZFE5ICZWbZzLrPGdQr0huOc45OVBbw8ex0fLMmjrDJI19ZNGdGnHaf2bcfxPdNJSUrwu0wRiSEK9CiwbVcZMxZuYubSzXy2uoCS8iBNEgMc1bklQzPSGNw1jX4dm9M17TACAe3Bi0jNFOhRpqS8ki9WF/LZqgKy121lUW4R5ZXev0PTpAR6tU/liHapdE07jC5pTekSum/fIoUmiTrsIdKY7S/Qwxo0bWZnAg8DCcDTzrk/VFufDEwBhgKFwDjn3NqDKTqepSQlcGpfr9sFvIBftqmYFZuKWb65mOWbivl8VSGbi3Op/n3bIiWRNqnJtElNJj21CempTUg7rAmpyYk0T0kiNSWR5smJNE9J9B6nJNGsSQIpSQkkJwbUfy8Sx+oMdDNLAB4DTgdygNlmNt05t6TKZtcCW51zR5jZeOCPwLiGKDgepSQlMKhrKwZ1bbXP8rKKIBuLdpOzdTfrt+wir7iUwh2lFOwso3BHKSvzdvDFmlK27y4nGOYfWsmJAVKSEkhJCnwX8ilJCaQkJpCcFCA5MUBiIEBigpGUECAxYCQmBEhKMBIDofvQ4yaJ31/vrTMSAoaZkWBGwLwTshIC3uNAwAhUWbfnefV1ZoReYyQEvPeous5C72tAYM8yAANj7/Oq27DndVWWW9Xta3ntns8SiWbh7KEfC6xyzq0BMLOXgfOAqoF+HnBf6PFrwKNmZk4DsQ9Kk8QA3dOb0T292X63c86xq6yS4pIKdpSWs72kgh0lFd8931FaSWlFJSXlQUrLKykp9x6XVFR5XF7J9pIKyiuCVASDVFQ6yvfcV7q9yyqDVAQdleF+g8SZ2r4M+G556MulyjZU+x6o/rVQ/Yui+vdGndvXUOP+3yGcz6i+/uBqrPPzI/x5YX/11uM7OtxNw/niH39MV647qWf4Hx6mcAK9M7C+yvMc4LjatnHOVZhZEZAOFFTdyMxuAG4A6Nat2wGWLNWZGc2SE0OXHUg5JJ8ZDO4N/H3DP0hl0BF0e25899xVeVx9XTBIleXe80rncM5RWcs6HDi893Xw3Wc4AOdw3h2uyuNgaB/DVXvtPs9dLctDLwzW8lq+ex7aZs/yKuraxam+D1R98+qvr+v9a/q479dQx3sc5GfW9fo6nh7AzyQ89dnfDHvLMLGBc+AAAAUSSURBVDds00BTW4YT6DV93VQvO5xtcM49CTwJ3kHRMD5bolQgYCQHEtCla0SiRzhDJnKArlWedwE21LaNmSUCLYEtkShQRETCE06gzwZ6mVkPM2sCjAemV9tmOnBl6PFFwH/Vfy4icmjV+QdzqE/8JuBdvGGLzzjnFpvZ/UCWc2468A/gn2a2Cm/PfHxDFi0iIt8XVg+oc24GMKPasnuqPC4BLo5saSIiUh867VBEJE4o0EVE4oQCXUQkTijQRUTihG9XWzSzfODbA3x5G6qdhRrD1JbopLZEn3hpBxxcW7o759rWtMK3QD8YZpZV2+UjY43aEp3UlugTL+2AhmuLulxEROKEAl1EJE7EaqA/6XcBEaS2RCe1JfrESzuggdoSk33oIiLyfbG6hy4iItUo0EVE4kTMBbqZnWlmy81slZnd4Xc9dTGzZ8wsz8wWVVnW2szeN7OVofu00HIzs0dCbVtgZkP8q3xfZtbVzD40s6VmttjMbg0tj8W2pJjZ12Y2P9SWX4eW9zCzr0JteSV0uWjMLDn0fFVofYaf9dfEzBLMbK6ZvRl6HpNtMbO1ZrbQzOaZWVZoWcz9jgGYWSsze83MloX+3wxr6LbEVKDb3gmrzwL6AxPMrL+/VdVpMnBmtWV3ADOdc72AmaHn4LWrV+h2AzDpENUYjgrgf51z/YDjgZ+Gfvax2JZSYIRz7mhgEHCmmR2PN7n5X0Nt2Yo3+TlUmQQd+Gtou2hzK7C0yvNYbsupzrlBVcZpx+LvGMDDwDvOub7A0Xj/Pg3bFheatzEWbsAw4N0qz+8E7vS7rjDqzgAWVXm+HOgYetwRWB56/AQwoabtou0G/Bs4PdbbAhwGzMGbJ7cASKz+u4Y3F8Cw0OPE0Hbmd+1V2tAlFA4jgDfxpoSM1basBdpUWxZzv2NAC+Cb6j/bhm5LTO2hU/OE1Z19quVgtHfObQQI3bcLLY+J9oX+TB8MfEWMtiXURTEPyAPeB1YD25xzFaFNqta7zyTowJ5J0KPF34BfAMHQ83Rity0OeM/MskOTykNs/o71BPKBZ0NdYU+bWTMauC2xFuhhTUYdw6K+fWaWCrwO/Mw5t31/m9awLGra4pyrdM4Nwtu7PRboV9NmofuobYuZjQbynHPZVRfXsGnUtyXkB865IXhdED81s+H72Taa25IIDAEmOecGAzvZ271Sk4i0JdYCPZwJq2PBZjPrCBC6zwstj+r2mVkSXpi/4JybFlock23Zwzm3DfgI77hAK/MmOYd9643mSdB/AIwxs7XAy3jdLn8jNtuCc25D6D4P+Bfel20s/o7lADnOua9Cz1/DC/gGbUusBXo4E1bHgqqTal+J1x+9Z/kPQ0e8jweK9vx55jczM7y5Y5c65x6qsioW29LWzFqFHjcFTsM7YPUh3iTn8P22ROUk6M65O51zXZxzGXj/H/7rnLuMGGyLmTUzs+Z7HgOjgEXE4O+Yc24TsN7M+oQWjQSW0NBt8fvgwQEcbDgbWIHX5/krv+sJo96XgI1AOd638LV4fZYzgZWh+9ahbQ1vFM9qYCGQ6Xf9VdpxIt6fgAuAeaHb2THalqOAuaG2LALuCS3vCXwNrAJeBZJDy1NCz1eF1vf0uw21tOsU4M1YbUuo5vmh2+I9/79j8XcsVN8gICv0e/YGkNbQbdGp/yIicSLWulxERKQWCnQRkTihQBcRiRMKdBGROKFAFxGJEwp0EZE4oUAXEYkT/w8H9reAcfCoSQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "d213bab112ee6222d3c7ae0b13bad4fa123e684288282252b000db52d3893657"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}